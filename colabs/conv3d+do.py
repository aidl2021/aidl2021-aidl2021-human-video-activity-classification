# -*- coding: utf-8 -*-
"""Conv3d+DO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EIuTdYK0VUc-4sj5VhxE-k6vXJeThreU
"""

import pandas as pd
import numpy as np
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import glob
import torchvision.transforms as transforms
from torchvision.transforms import functional
from torchvision.io import read_image
from torchvision.io.image import read_file
from torch import torch
import cv2
from sklearn import preprocessing
import torch.nn.functional as F
import matplotlib.pyplot as plt
from PIL import Image
import os
import torchvision
import torch.nn as nn
from torch import optim as optim
from torchsummary import summary

from google.colab import drive
drive.mount('/content/drive')


class NTUDataset(Dataset):
    def __init__(self, criteria, config):
        self.criteria = criteria
        self.files = glob.glob(self.criteria)
        #self.load_as_images = load_as_images
        self.transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize(
            (272, 480)), transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])
        self.imageResize = config["imageResize"]
        self.imageResizeWidth = config["imageResizeWidth"]
        self.imageResizeHeight = config["imageResizeHeight"]
        self.seq_len = config["seq_len"]
        self.labels = []
        for f in self.files:
            self.labels.append(f[len(f)-12:-8])

        self.labels.sort()
        self.labels = list(set(self.labels))
        pass

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        path = self.files[idx]
        label = path[len(path)-12:-8]

        value = self.labels.index(label)

        vidcap = cv2.VideoCapture(path)
        success, image = vidcap.read()
        count = 0
        fcount = 0

        seq = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        seq = self.transform(seq)
        seq = torch.unsqueeze(seq, 0)
        while success:
            fcount += 1
            if (fcount) % 10 == 0:

                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                # trans1=transforms.ToPILImage()
                # trans2=transforms.ToTensor()
                image = self.transform(image)
                # plt.imshow(image)
                image = torch.unsqueeze(image, 0)

                # cv2.imwrite('../savedimage.jpg',image)

                seq = torch.cat((seq, image), 0)

                count += 1
                if seq.shape[0] == 16:
                    break
            success, image = vidcap.read()
            vidcap.release

        lab = value
        lab = torch.tensor(lab, dtype=torch.long)

        if seq.shape[0] < 16:
            pad = torch.zeros(16-seq.shape[0], 3, 272, 480)
            seq = torch.cat((seq, pad), 0)

        seq = seq.permute(1, 0, 2, 3)  # Solo para el caso de Conv3d

        return seq, lab, count


config = {
    "lr": 0.0001,
    "batch_size": 4,
    "epochs": 15,
    "h1": 64,
    "h2": 128,
    "h3": 256,
        "h4": 4096,
        "h5": 1024,
        "features": 60,
        "imageInputWidth": 1920,
        "imageInputHeight": 1080,
        "imageResize": True,
        "imageResizeWidth": 480,
        "imageResizeHeight": 272,
        "seq_len": 10,
        "hidden_size": 512,
        "num_layers": 1,
        "input_size": 1000,
}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def splitDataset(dataset: Dataset, train=90, test=5, val=5):
    len = dataset.__len__()
    propsum = train+test+val
    longtrain = int(train * len / propsum)
    longtest = int(test * len / propsum)
    longval = int(len - longtrain - longtest)
    return torch.utils.data.random_split(dataset, [longtrain, longtest, longval])


drive.mount('/content/drive')

dataset = NTUDataset("/content/drive/MyDrive/nturgb+d_rgb/*.avi", config)

train_dataset, val_dataset, test_dataset = splitDataset(dataset, 60, 15, 25)
train_loader = DataLoader(
    train_dataset, batch_size=config["batch_size"], shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=config["batch_size"])
test_loader = DataLoader(test_dataset, batch_size=config["batch_size"])


def accuracy(labels, outputs):
    preds = outputs.argmax(-1)
    acc = (preds == labels.view_as(preds)
           ).float().detach().cpu().numpy().mean()
    return acc


class MyModel(nn.Module):
    def __init__(self, seq_len=10):
        super().__init__()
        self.seq_len = seq_len
        self.conv1 = nn.Conv3d(
            in_channels=3, out_channels=32, kernel_size=3, padding=1)
        self.pool = nn.MaxPool3d((2, 4, 4))
        # self.conv2=nn.Conv3d(in_channels=32,out_channels=64,kernel_size=3,padding=1)
        self.conv3 = nn.Conv3d(
            in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.conv4 = nn.Conv3d(
            in_channels=64, out_channels=128, kernel_size=3, padding=1)
        self.dropout = nn.Dropout3d(0.5)
        self.dropoutl = nn.Dropout(0.5)

        # self.fcconv= nn.Linear(261120,10240)#65280
        self.relu = nn.ReLU()
        self.fc1 = nn.Linear(261120, 1024)
        # self.fc2=nn.Linear(5000,2048)
        self.fc3 = nn.Linear(1024, 60)
        # self.softmax=nn.LogSoftmax(dim=1)
        self.flat = nn.Flatten(start_dim=1, end_dim=-1)
        self.batchnorm1 = nn.BatchNorm3d(32)
        self.batchnorm2 = nn.BatchNorm3d(64)
        self.batchnorm3 = nn.BatchNorm3d(128)

    def forward(self, x):
        x = self.pool(self.relu(self.conv1(x)))
        x = self.batchnorm1(x)
        # x=self.dropout(x)
        #x= self.pool(self.relu(self.conv2(x)))
        x = self.pool(self.relu(self.conv3(x)))
        x = self.batchnorm2(x)
        # x=self.dropout(x)
        x = self.relu(self.conv4(x))
        x = self.batchnorm3(x)

        x = self.flat(x)
        x = self.dropoutl(x)
        x = F.relu(self.fc1(x))
        x = self.dropoutl(x)
        #x= F.relu(self.fc2(x))
        x = self.fc3(x)
        # x=self.softmax(self.fc2(x))

        return x


def train(config, model, train_loader, optimizer):
    model.train()
    accs, losses = [], []
    lfunct = nn.CrossEntropyLoss()

    for x, y, count in train_loader:

        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()

        hn = model(x)
        loss = lfunct(hn, y)
        loss.backward()
        # Optimitzador
        optimizer.step()
        acc = accuracy(y, hn)
        # Ho posem al vector de losses i accuracies
        losses.append(loss.item())
        accs.append(acc.item())
        # print(loss,acc)

    return np.mean(losses), np.mean(accs)


def test(model, val_loader):
    accs, losses = [], []
    lfunct = nn.CrossEntropyLoss()
    with torch.no_grad():
        model.eval()
        for x, y, count in val_loader:
            x, y = x.to(device), y.to(device)

            hn = model(x)
            loss = lfunct(hn, y)
            acc = accuracy(y, hn)
            losses.append(loss.item())
            accs.append(acc.item())

        return np.mean(losses), np.mean(accs)


model = MyModel(config["seq_len"]).to(device)

optimizer = optim.Adam(model.parameters(), config["lr"], weight_decay=0.0001)
root = '/content/drive/MyDrive/results/checkpoint1'
 checkpointFileName = f"{root}.pt"
  train_from_checkpoint = False
   if train_from_checkpoint:
        checkpoint = torch.load(checkpointFileName, map_location="cuda:0")

        train_acc, train_loss = (
            checkpoint["trainAccuracies"],
            checkpoint["trainLosses"],
        )

        test_acc, test_loss = (
            checkpoint["testAccuracies"],
            checkpoint["testLosses"],
        )
        init_epoch = checkpoint["initialEpoch"]
        model.load_state_dict(checkpoint["modelStateDict"])
        model.to(device)
        optimizer.load_state_dict(checkpoint["optimizerStateDict"])
        for epoch in range(init_epoch, config["epochs"]):
            loss, acc = train(config, model, train_loader, optimizer)
            losst, acct = test(model, val_loader)
            train_loss.append(loss)
            test_loss.append(losst)
            train_acc.append(acc)
            test_acc.append(acct)
            print(
                f"Epoch {epoch} loss={loss:.12f} acc={acc:.12f} lossT={losst:.12f} accT={acct:.12f}")

    else:
        train_loss = []
        test_loss = []
        train_acc = []
        test_acc = []
        for epoch in range(config["epochs"]):
            loss, acc = train(config, model, train_loader, optimizer)
            losst, acct = test(model, val_loader)
            train_loss.append(loss)
            test_loss.append(losst)
            train_acc.append(acc)
            test_acc.append(acct)
            print(
                f"Epoch {epoch} loss={loss:.12f} acc={acc:.12f} lossT={losst:.12f} accT={acct:.12f}")

    checkpoint = {
        "modelStateDict": model.state_dict(),
        "optimizerStateDict": optimizer.state_dict(),
        "trainLosses": train_loss,
        "trainAccuracies": train_acc,
        "testLosses": test_loss,
        "testAccuracies": test_acc,
            "initialEpoch": epoch,
            "TRAINACCURACY": acc,
            "TRAINLOSS": loss,
    }
    torch.save(checkpoint, f"{root}.pt")

root = '/content/drive/MyDrive/results/checkpoint1'
checkpointFileName = f"{root}.pt"

model = MyModel(config["seq_len"]).to(device)
optimizer = optim.Adam(model.parameters(), config["lr"])
checkpoint = torch.load(checkpointFileName, map_location="cpu")
train_acc, train_loss = (
    checkpoint["trainAccuracies"],
    checkpoint["trainLosses"],
)

test_acc, test_loss = (
    checkpoint["testAccuracies"],
    checkpoint["testLosses"],
)


model.load_state_dict(checkpoint["modelStateDict"])
optimizer.load_state_dict(checkpoint["optimizerStateDict"])

plt.figure(figsize=(10, 8))
plt.subplot(2, 1, 1)
plt.xlabel('Epoch')
plt.ylabel('CrossEntropyLoss')
plt.plot(train_loss, label='train')
plt.plot(test_loss, label='eval')
plt.legend()
plt.subplot(2, 1, 2)
plt.xlabel('Epoch')
plt.ylabel('Eval Accuracy [%]')
plt.plot(train_acc, label='train')
plt.plot(test_acc, label='eval')
plt.legend()

print(model.forward)

model1 = MyModel(config["seq_len"])
summary(model1, input_size=(3, 16, config['imageResizeHeight'],
        config['imageResizeWidth']), batch_size=config['batch_size'])
